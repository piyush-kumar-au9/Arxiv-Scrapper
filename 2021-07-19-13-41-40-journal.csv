,Name,Author,Abstract,Download link
0,Machine-learning Kondo physics using variational autoencoders,"['Cole Miles', 'Matthew R. Carbone', 'Erica J. Sturm', 'Deyu Lu', 'Andreas Weichselbaum', 'Kipton Barros', 'Robert M. Konik']","We employ variational autoencoders to extract physical insight from a dataset of one-particle Anderson impurity model spectral functions. Autoencoders are trained to find a low-dimensional, latent space representation that faithfully characterizes each element of the training set, as measured by a reconstruction error. Variational autoencoders, a probabilistic generalization of standard autoencoders, further condition the learned latent space to promote highly interpretable features. In our study, we find that the learned latent space components strongly correlate with well known, but nontrivial, parameters that characterize emergent behaviors in the Anderson impurity model. In particular, one latent space component correlates with particle-hole asymmetry, while another is in near one-to-one correspondence with the Kondo temperature, a dynamically generated low-energy scale in the impurity model. With symbolic regression, we model this component as a function of bare physical input parameters and ""rediscover"" the non-perturbative formula for the Kondo temperature. The machine learning pipeline we develop opens opportunities to discover new domain knowledge in other physical systems.
        △ Less",https://arxiv.org/pdf/2107.08013
1,Uncertainty Prediction for Machine Learning Models of Material Properties,"['Francesca Tavazza', 'Brian De Cost', 'Kamal Choudhary']","Uncertainty quantification in Artificial Intelligence (AI)-based predictions of material properties is of immense importance for the success and reliability of AI applications in material science. While confidence intervals are commonly reported for machine learning (ML) models, prediction intervals, i.e., the evaluation of the uncertainty on each prediction, are seldomly available. In this work we compare 3 different approaches to obtain such individual uncertainty, testing them on 12 ML-physical properties. Specifically, we investigated using the Quantile loss function, machine learning the prediction intervals directly and using Gaussian Processes. We identify each approachs advantages and disadvantages and end up slightly favoring the modeling of the individual uncertainties directly, as it is the easiest to fit and, in most cases, minimizes over-and under-estimation of the predicted errors. All data for training and testing were taken from the publicly available JARVIS-DFT database, and the codes developed for computing the prediction intervals are available through JARVIS-Tools.
        △ Less",https://arxiv.org/pdf/2107.07997
2,A Multimodal Machine Learning Framework for Teacher Vocal Delivery Evaluation,"['Hang Li', 'Yu Kang', 'Yang Hao', 'Wenbiao Ding', 'Zhongqin Wu', 'Zitao Liu']","The quality of vocal delivery is one of the key indicators for evaluating teacher enthusiasm, which has been widely accepted to be connected to the overall course qualities. However, existing evaluation for vocal delivery is mainly conducted with manual ratings, which faces two core challenges: subjectivity and time-consuming. In this paper, we present a novel machine learning approach that utilizes pairwise comparisons and a multimodal orthogonal fusing algorithm to generate large-scale objective evaluation results of the teacher vocal delivery in terms of fluency and passion. We collect two datasets from real-world education scenarios and the experiment results demonstrate the effectiveness of our algorithm. To encourage reproducible results, we make our code public available at \url{https://github.com/tal-ai/ML4VocalDelivery.git}.
        △ Less",https://arxiv.org/pdf/2107.07956
3,A Preliminary Study on Automatic Motion Artifacts Detection in Electrodermal Activity Data Using Machine Learning,"['Md Billal Hossain', 'Hugo Fernando Posada-Quintero', 'Youngsun Kong', 'Riley McNaboe', 'Ki Chon']","The electrodermal activity (EDA) signal is a sensitive and non-invasive surrogate measure of sympathetic function. Use of EDA has increased in popularity in recent years for such applications as emotion and stress recognition; assessment of pain, fatigue, and sleepiness; diagnosis of depression and epilepsy; and other uses. Recently, there have been several studies using ambulatory EDA recordings, which are often quite useful for analysis of many physiological conditions. Because ambulatory monitoring uses wearable devices, EDA signals are often affected by noise and motion artifacts. An automated noise and motion artifact detection algorithm is therefore of utmost importance for accurate analysis and evaluation of EDA signals. In this paper, we present machine learning-based algorithms for motion artifact detection in EDA signals. With ten subjects, we collected two simultaneous EDA signals from the right and left hands, while instructing the subjects to move only the right hand. Using these data, we proposed a cross-correlation-based approach for non-biased labeling of EDA data segments. A set of statistical, spectral and model-based features were calculated which were then subjected to a feature selection algorithm. Finally, we trained and validated several machine learning methods using a leave-one-subject-out approach. The classification accuracy of the developed model was 83.85% with a standard deviation of 4.91%, which was better than a recent standard method that we considered for comparison to our algorithm.
        △ Less",https://arxiv.org/pdf/2107.07650
4,Understanding Heating in Active Region Cores through Machine Learning II. Classifying Observations,"['W. T. Barnes', 'S. J. Bradshaw', 'N. M. Viall']","Constraining the frequency of energy deposition in magnetically-closed active region cores requires sophisticated hydrodynamic simulations of the coronal plasma and detailed forward modeling of the optically-thin line-of-sight integrated emission. However, understanding which set of model inputs best matches a set of observations is complicated by the need for any proposed heating model to simultaneously satisfy multiple observable constraints. In this paper, we train a random forest classification model on a set of forward-modeled observable quantities, namely the emission measure slope, the peak temperature of the emission measure distribution, and the time lag and maximum cross-correlation between multiple pairs of AIA channels. We then use our trained model to classify the heating frequency in every pixel of active region NOAA 1158 using the observed emission measure slopes, peak temperatures, time lags, and maximum cross-correlations and are able to map the heating frequency across the entire active region. We find that high-frequency heating dominates in the inner core of the active region while intermediate frequency dominates closer to the periphery of the active region. Additionally, we assess the importance of each observed quantity in our trained classification model and find that the emission measure slope is the dominant feature in deciding with which heating frequency a given pixel is most consistent. The technique presented here offers a very promising and widely applicable method for assessing observations in terms of detailed forward models given an arbitrary number of observable constraints.
        △ Less",https://arxiv.org/pdf/2107.07612
5,Arrow: A RISC-V Vector Accelerator for Machine Learning Inference,"['Imad Al Assir', 'Mohamad El Iskandarani', 'Hadi Rayan Al Sandid', 'Mazen A. R. Saghir']","In this paper we present Arrow, a configurable hardware accelerator architecture that implements a subset of the RISC-V v0.9 vector ISA extension aimed at edge machine learning inference. Our experimental results show that an Arrow co-processor can execute a suite of vector and matrix benchmarks fundamental to machine learning inference 2 - 78x faster than a scalar RISC processor while consuming 20% - 99% less energy when implemented in a Xilinx XC7A200T-1SBG484C FPGA.
        △ Less",https://arxiv.org/pdf/2107.07169
6,Transformer-based Machine Learning for Fast SAT Solvers and Logic Synthesis,"['Feng Shi', 'Chonghan Lee', 'Mohammad Khairul Bashar', 'Nikhil Shukla', 'Song-Chun Zhu', 'Vijaykrishnan Narayanan']","CNF-based SAT and MaxSAT solvers are central to logic synthesis and verification systems. The increasing popularity of these constraint problems in electronic design automation encourages studies on different SAT problems and their properties for further computational efficiency. There has been both theoretical and practical success of modern Conflict-driven clause learning SAT solvers, which allows solving very large industrial instances in a relatively short amount of time. Recently, machine learning approaches provide a new dimension to solving this challenging problem. Neural symbolic models could serve as generic solvers that can be specialized for specific domains based on data without any changes to the structure of the model. In this work, we propose a one-shot model derived from the Transformer architecture to solve the MaxSAT problem, which is the optimization version of SAT where the goal is to satisfy the maximum number of clauses. Our model has a scale-free structure which could process varying size of instances. We use meta-path and self-attention mechanism to capture interactions among homogeneous nodes. We adopt cross-attention mechanisms on the bipartite graph to capture interactions among heterogeneous nodes. We further apply an iterative algorithm to our model to satisfy additional clauses, enabling a solution approaching that of an exact-SAT problem. The attention mechanisms leverage the parallelism for speedup. Our evaluation indicates improved speedup compared to heuristic approaches and improved completion rate compared to machine learning approaches.
        △ Less",https://arxiv.org/pdf/2107.07116
7,Machine learning for materials discovery: two-dimensional topological insulators,"['Gabriel R. Schleder', 'Bruno Focassio', 'Adalberto Fazzio']","One of the main goals and challenges of materials discovery is to find the best candidates for each interest property or application. Machine learning rises in this context to efficiently optimize this search, exploring the immense materials space, consisting of simultaneously the atomic, compositional, and structural spaces. Topological insulators, presenting symmetry-protected metallic edge states, are a promising class of materials for different applications. However, further, development is limited by the scarcity of viable candidates. Here we present and discuss machine learning-accelerated strategies for searching the materials space for two-dimensional topological materials. We show the importance of detailed investigations of each machine learning component, leading to different results. Using recently created databases containing thousands of ab initio calculations of 2D materials, we train machine learning models capable of determining the electronic topology of materials, with an accuracy of over 90%. We can then generate and screen thousands of novel materials, efficiently predicting their topological character without the need for a priori structural knowledge. We discover 56 non-trivial materials, of which 17 novel insulating candidates for further investigation, for which we corroborate their topological properties with density functional theory calculations. This strategy is 10\times more efficient than the trial-and-error approach while few orders of magnitude faster and is a proof of concept for guiding improved materials discovery search strategies.
        △ Less",https://arxiv.org/pdf/2107.07028
8,Towards Quantifying the Carbon Emissions of Differentially Private Machine Learning,"['Rakshit Naidu', 'Harshita Diddee', 'Ajinkya Mulay', 'Aleti Vardhan', 'Krithika Ramesh', 'Ahmed Zamzam']","In recent years, machine learning techniques utilizing large-scale datasets have achieved remarkable performance. Differential privacy, by means of adding noise, provides strong privacy guarantees for such learning algorithms. The cost of differential privacy is often a reduced model accuracy and a lowered convergence speed. This paper investigates the impact of differential privacy on learning algorithms in terms of their carbon footprint due to either longer run-times or failed experiments. Through extensive experiments, further guidance is provided on choosing the noise levels which can strike a balance between desired privacy levels and reduced carbon emissions.
        △ Less",https://arxiv.org/pdf/2107.06946
9,A Framework for Machine Learning of Model Error in Dynamical Systems,"['Matthew E. Levine', 'Andrew M. Stuart']","The development of data-informed predictive models for dynamical systems is of widespread interest in many disciplines. We present a unifying framework for blending mechanistic and machine-learning approaches to identify dynamical systems from data. We compare pure data-driven learning with hybrid models which incorporate imperfect domain knowledge. We cast the problem in both continuous- and discrete-time, for problems in which the model error is memoryless and in which it has significant memory, and we compare data-driven and hybrid approaches experimentally. Our formulation is agnostic to the chosen machine learning model.
  Using Lorenz '63 and Lorenz '96 Multiscale systems, we find that hybrid methods substantially outperform solely data-driven approaches in terms of data hunger, demands for model complexity, and overall predictive performance. We also find that, while a continuous-time framing allows for robustness to irregular sampling and desirable domain-interpretability, a discrete-time framing can provide similar or better predictive performance, especially when data are undersampled and the vector field cannot be resolved.
  We study model error from the learning theory perspective, defining excess risk and generalization error; for a linear model of the error used to learn about ergodic dynamical systems, both errors are bounded by terms that diminish with the square-root of T. We also illustrate scenarios that benefit from modeling with memory, proving that continuous-time recurrent neural networks (RNNs) can, in principle, learn memory-dependent model error and reconstruct the original system arbitrarily well; numerical results depict challenges in representing memory by this approach. We also connect RNNs to reservoir computing and thereby relate the learning of memory-dependent error to recent work on supervised learning between Banach spaces using random features.
        △ Less",https://arxiv.org/pdf/2107.06658
10,Generative and reproducible benchmarks for comprehensive evaluation of machine learning classifiers,"['Patryk Orzechowski', 'Jason H. Moore']","Understanding the strengths and weaknesses of machine learning (ML) algorithms is crucial for determine their scope of application. Here, we introduce the DIverse and GENerative ML Benchmark (DIGEN) - a collection of synthetic datasets for comprehensive, reproducible, and interpretable benchmarking of machine learning algorithms for classification of binary outcomes. The DIGEN resource consists of 40 mathematical functions which map continuous features to discrete endpoints for creating synthetic datasets. These 40 functions were discovered using a heuristic algorithm designed to maximize the diversity of performance among multiple popular machine learning algorithms thus providing a useful test suite for evaluating and comparing new methods. Access to the generative functions facilitates understanding of why a method performs poorly compared to other algorithms thus providing ideas for improvement. The resource with extensive documentation and analyses is open-source and available on GitHub.
        △ Less",https://arxiv.org/pdf/2107.06475
11,Adaptive Machine Learning for Time-Varying Systems: Low Dimensional Latent Space Tuning,['Alexander Scheinker'],"Machine learning (ML) tools such as encoder-decoder convolutional neural networks (CNN) can represent incredibly complex nonlinear functions which map between combinations of images and scalars. For example, CNNs can be used to map combinations of accelerator parameters and images which are 2D projections of the 6D phase space distributions of charged particle beams as they are transported between various particle accelerator locations. Despite their strengths, applying ML to time-varying systems, or systems with shifting distributions, is an open problem, especially for large systems for which collecting new data for re-training is impractical or interrupts operations. Particle accelerators are one example of large time-varying systems for which collecting detailed training data requires lengthy dedicated beam measurements which may no longer be available during regular operations. We present a recently developed method of adaptive ML for time-varying systems. Our approach is to map very high (N>100k) dimensional inputs (a combination of scalar parameters and images) into the low dimensional (N~2) latent space at the output of the encoder section of an encoder-decoder CNN. We then actively tune the low dimensional latent space-based representation of complex system dynamics by the addition of an adaptively tuned feedback vector directly before the decoder sections builds back up to our image-based high-dimensional phase space density representations. This method allows us to learn correlations within and to quickly tune the characteristics of incredibly high parameter systems and to track their evolution in real time based on feedback without massive new data sets for re-training.
        △ Less",https://arxiv.org/pdf/2107.06207
12,ML-Quest: A Game for Introducing Machine Learning Concepts to K-12 Students,"['Shruti Priya', 'Shubhankar Bhadra', 'Sridhar Chimalakonda']","Today, Machine Learning (ML) is of a great importance to society due to the availability of huge data and high computational resources. This ultimately led to the introduction of ML concepts at multiple levels of education including K-12 students to promote computational thinking. However, teaching these concepts to K-12 through traditional methodologies such as video lectures and books is challenging. Many studies in the literature have reported that using interactive environments such as games to teach computational thinking and programming improves retention capacity and motivation among students. Therefore, introducing ML concepts using a game might enhance students' understanding of the subject and motivate them to learn further. However, we are not aware of any existing game which explicitly focuses on introducing ML concepts to students using game play. Hence, in this paper, we propose ML-Quest, a 3D video game to provide conceptual overview of three ML concepts: Supervised Learning, Gradient Descent and K-Nearest Neighbor (KNN) Classification. The crux of the game is to introduce the definition and working of these concepts, which we call conceptual overview, in a simulated scenario without overwhelming students with the intricacies of ML. The game has been predominantly evaluated for its usefulness and player experience using the Technology Acceptance Model (TAM) model with the help of 23 higher-secondary school students. The survey result shows that around 70% of the participants either agree or strongly agree that the ML-Quest is quite interactive and useful in introducing them to ML concepts.
        △ Less",https://arxiv.org/pdf/2107.06206
13,Towards Machine Learning-Enabled Context Adaption for Reliable Aerial Mesh Routing,"['Cedrik Schüler', 'Benjamin Sliwa', 'Christian Wietfeld']","In this paper, we present Context-Adaptive PARRoT (CA-PARRoT) as an extension of our previous work Predictive Ad-hoc Routing fueled by Reinforcement learning and Trajectory knowledge (PARRoT). Short-term effects, as occurring in urban surroundings, have shown to have a negative impact on the Reinforcement Learning (RL)-based routing process. Therefore, we add a timer-based compensation mechanism to the update process and introduce a hybrid Machine Learning (ML) approach to classify Radio Environment Prototypes (REPs) with a dedicated ML component and enable the protocol for autonomous context adaption. The performance of the novel protocol is evaluated in comprehensive network simulations considering different REPs and is compared to well-known established routing protocols for Mobile Ad-hoc Networks (MANETs). The results show, that CA-PARRoT is capable to compensate the challenges confronted with in different REPs and to improve its Key Performance Indicators (KPIs) up to 23% compared to PARRoT, and outperform established routing protocols by up to 50 %.
        △ Less",https://arxiv.org/pdf/2107.06190
14,On doubly robust inference for double machine learning,"['Oliver Dukes', 'Stijn Vansteelandt', 'David Whitney']","Due to concerns about parametric model misspecification, there is interest in using machine learning to adjust for confounding when evaluating the causal effect of an exposure on an outcome. Unfortunately, exposure effect estimators that rely on machine learning predictions are generally subject to so-called plug-in bias, which can render naive p-values and confidence intervals invalid. Progress has been made via proposals like targeted maximum likelihood estimation and more recently double machine learning, which rely on learning the conditional mean of both the outcome and exposure. Valid inference can then be obtained so long as both predictions converge (sufficiently fast) to the truth. Focusing on partially linear regression models, we show that a specific implementation of the machine learning techniques can yield exposure effect estimators that have small bias even when one of the first-stage predictions does not converge to the truth. The resulting tests and confidence intervals are doubly robust. We also show that the proposed estimators may fail to be regular when only one nuisance parameter is consistently estimated; nevertheless, we observe in simulation studies that our proposal leads to reduced bias and improved confidence interval coverage in moderate samples.
        △ Less",https://arxiv.org/pdf/2107.06124
15,On Choice of Hyper-parameter in Extreme Value Theory based on Machine Learning Techniques,['Chikara Nakamura'],"Extreme value theory (EVT) is a statistical tool for analysis of extreme events. It has a strong theoretical background, however, we need to choose hyper-parameters
  to apply EVT. In recent studies of machine learning, techniques of choosing hyper-parameters have been well-studied. In this paper, we propose a new method of choosing hyper-parameters in EVT based on machine learning techniques. We also experiment our method to real-world data and show good usability of our method.
        △ Less",https://arxiv.org/pdf/2107.06074
16,Parametrization of Non-Bonded Force Field Terms for Metal-Organic Frameworks Using Machine Learning Approach,"['Vadim V. Korolev', 'Yurii M. Nevolin', 'Thomas A. Manz', 'Pavel V. Protsenko']","The enormous structural and chemical diversity of metal-organic frameworks (MOFs) forces researchers to actively use simulation techniques on an equal footing with experiments. MOFs are widely known for outstanding adsorption properties, so precise description of host-guest interactions is essential for high-throughput screening aimed at ranking the most promising candidates. However, highly accurate ab initio calculations cannot be routinely applied to model thousands of structures due to the demanding computational costs. On the other side, methods based on force field (FF) parametrization suffer from low transferability. To resolve this accuracy-efficiency dilemma, we apply the machine learning (ML) approach. The trained models reproduce atom-in-material quantities, including partial charges, polarizabilities, dispersion coefficients, quantum Drude oscillator and electron cloud parameters within the accuracy of underlying density functional theory method. The aforementioned FF precursors make it possible to thoroughly describe non-covalent interactions typical for MOF-adsorbate systems: electrostatic, dispersion, polarization, and short-range repulsion. The presented approach can also significantly facilitate hybrid atomistic simulations/ML workflows.
        △ Less",https://arxiv.org/pdf/2107.06044
17,AutoScore-Imbalance: An interpretable machine learning tool for development of clinical scores with rare events data,"['Han Yuan', 'Feng Xie', 'Marcus Eng Hock Ong', 'Yilin Ning', 'Marcel Lucas Chee', 'Seyed Ehsan Saffari', 'Hairil Rizal Abdullah', 'Benjamin Alan Goldstein', 'Bibhas Chakraborty', 'Nan Liu']","Background: Medical decision-making impacts both individual and public health. Clinical scores are commonly used among a wide variety of decision-making models for determining the degree of disease deterioration at the bedside. AutoScore was proposed as a useful clinical score generator based on machine learning and a generalized linear model. Its current framework, however, still leaves room for improvement when addressing unbalanced data of rare events. Methods: Using machine intelligence approaches, we developed AutoScore-Imbalance, which comprises three components: training dataset optimization, sample weight optimization, and adjusted AutoScore. All scoring models were evaluated on the basis of their area under the curve (AUC) in the receiver operating characteristic analysis and balanced accuracy (i.e., mean value of sensitivity and specificity). By utilizing a publicly accessible dataset from Beth Israel Deaconess Medical Center, we assessed the proposed model and baseline approaches in the prediction of inpatient mortality. Results: AutoScore-Imbalance outperformed baselines in terms of AUC and balanced accuracy. The nine-variable AutoScore-Imbalance sub-model achieved the highest AUC of 0.786 (0.732-0.839) while the eleven-variable original AutoScore obtained an AUC of 0.723 (0.663-0.783), and the logistic regression with 21 variables obtained an AUC of 0.743 (0.685-0.800). The AutoScore-Imbalance sub-model (using down-sampling algorithm) yielded an AUC of 0. 0.771 (0.718-0.823) with only five variables, demonstrating a good balance between performance and variable sparsity. Conclusions: The AutoScore-Imbalance tool has the potential to be applied to highly unbalanced datasets to gain further insight into rare medical events and to facilitate real-world clinical decision-making.
        △ Less",https://arxiv.org/pdf/2107.06039
18,Representing individual electronic states in crystals for machine learning quasiparticle band structures,"['Nikolaj Rørbæk Knøsgaard', 'Kristian Sommer Thygesen']","We address the problem of representing quantum states of electrons in a solid for the purpose of machine leaning state-specific electronic properties. Specifically, we construct a fingerprint based on energy decomposed operator matrix elements (ENDOME) and radially decomposed projected density of states (RAD-PDOS), which are both obtainable from a standard density functional theory (DFT) calculation. Using such fingerprints we train a gradient boosting model on a set of 46k G_0W_0 quasiparticle energies. The resulting model predicts the self-energy correction of states in materials not seen by the model with a mean absolute error of 0.14 eV. By including the material's calculated dielectric constant in the fingerprint the error can be further reduced by 30%, which we find is due to an enhanced ability to learn the correlation/screening part of the self-energy. Our work paves the way for accurate estimates of quasiparticle band structures at the cost of a standard DFT calculation.
        △ Less",https://arxiv.org/pdf/2107.06029
19,Machine-learning potentials enable predictive \textit{and} tractable high-throughput screening of random alloys,"['Max Hodapp', 'Alexander Shapeev']","We present an automated procedure for computing stacking fault energies in random alloys from large-scale simulations using moment tensor potentials (MTPs) with the accuracy of density functional theory (DFT). To that end, we develop an algorithm for training MTPs on random alloys. In the first step, our algorithm constructs a set of ~10000 or more training candidate configurations with 50-100 atoms that are representative for the atomic neighborhoods occurring in the large-scale simulation. In the second step, we use active learning to reduce this set to ~100 most distinct configurations - for which DFT energies and forces are computed and on which the potential is ultimately trained. We validate our algorithm for the MoNbTa medium-entropy alloy by showing that the MTP reproduces the DFT \frac{1}{4}[111] unstable stacking fault energy over the entire compositional space up to a few percent.
  Contrary to state-of-the-art methods, e.g., the coherent potential approximation (CPA) or special quasi-random structures (SQSs), our algorithm naturally accounts for relaxation, is not limited by DFT cell sizes, and opens opportunities to efficiently investigate follow-up problems, such as chemical ordering. In a broader sense, our algorithm can be easily modified to compute related properties of random alloys, for instance, misfit volumes, or grain boundary energies. Moreover, it forms the basis for an efficient construction of MTPs to be used in large-scale simulations of multicomponent systems.
        △ Less",https://arxiv.org/pdf/2107.05620
20,Nonlinear Least Squares for Large-Scale Machine Learning using Stochastic Jacobian Estimates,['Johannes J. Brust'],"For large nonlinear least squares loss functions in machine learning we exploit the property that the number of model parameters typically exceeds the data in one batch. This implies a low-rank structure in the Hessian of the loss, which enables effective means to compute search directions. Using this property, we develop two algorithms that estimate Jacobian matrices and perform well when compared to state-of-the-art methods.
        △ Less",https://arxiv.org/pdf/2107.05598
21,Investor Behavior Modeling by Analyzing Financial Advisor Notes: A Machine Learning Perspective,"['Cynthia Pagliaro', 'Dhagash Mehta', 'Han-Tai Shiao', 'Shaofei Wang', 'Luwei Xiong']","Modeling investor behavior is crucial to identifying behavioral coaching opportunities for financial advisors. With the help of natural language processing (NLP) we analyze an unstructured (textual) dataset of financial advisors' summary notes, taken after every investor conversation, to gain first ever insights into advisor-investor interactions. These insights are used to predict investor needs during adverse market conditions; thus allowing advisors to coach investors and help avoid inappropriate financial decision-making. First, we perform topic modeling to gain insight into the emerging topics and trends. Based on this insight, we construct a supervised classification model to predict the probability that an advised investor will require behavioral coaching during volatile market periods. To the best of our knowledge, ours is the first work on exploring the advisor-investor relationship using unstructured data. This work may have far-reaching implications for both traditional and emerging financial advisory service models like robo-advising.
        △ Less",https://arxiv.org/pdf/2107.05592
22,OmniLytics: A Blockchain-based Secure Data Market for Decentralized Machine Learning,"['Jiacheng Liang', 'Wensi Jiang', 'Songze Li']","We propose OmniLytics, a blockchain-based secure data trading marketplace for machine learning applications. Utilizing OmniLytics, many distributed data owners can contribute their private data to collectively train a ML model requested by some model owners, and get compensated for data contribution. OmniLytics enables such model training while simultaneously providing 1) model security against curious data owners; 2) data security against curious model and data owners; 3) resilience to malicious data owners who provide faulty results to poison model training; and 4) resilience to malicious model owner who intents to evade the payment. OmniLytics is implemented as a smart contract on the Ethereum blockchain to guarantee the atomicity of payment. In OmniLytics, a model owner publishes encrypted initial model on the contract, over which the participating data owners compute gradients using their private data, and securely aggregate the gradients through the contract. Finally, the contract reimburses the data owners, and the model owner decrypts the aggregated model update. We implement a working prototype of OmniLytics on Ethereum, and perform extensive experiments to measure its gas cost and execution time under various parameter combinations, demonstrating its high computation and cost efficiency and strong practicality.
        △ Less",https://arxiv.org/pdf/2107.05252
23,Fock State-enhanced Expressivity of Quantum Machine Learning Models,"['Beng Yee Gan', 'Daniel Leykam', 'Dimitris G. Angelakis']","The data-embedding process is one of the bottlenecks of quantum machine learning, potentially negating any quantum speedups. In light of this, more effective data-encoding strategies are necessary. We propose a photonic-based bosonic data-encoding scheme that embeds classical data points using fewer encoding layers and circumventing the need for nonlinear optical components by mapping the data points into the high-dimensional Fock space. The expressive power of the circuit can be controlled via the number of input photons. Our work shed some light on the unique advantages offers by quantum photonics on the expressive power of quantum machine learning models. By leveraging the photon-number dependent expressive power, we propose three different noisy intermediate-scale quantum-compatible binary classification methods with different scaling of required resources suitable for different supervised classification tasks.
        △ Less",https://arxiv.org/pdf/2107.05224
24,Sampling Lattices in Semi-Grand Canonical Ensemble with Autoregressive Machine Learning,"['James Damewood', 'Daniel Schwalbe-Koda', 'Rafael Gomez-Bombarelli']","Calculating thermodynamic potentials and observables efficiently and accurately is key for the application of statistical mechanics simulations to materials science. However, naive Monte Carlo approaches, on which such calculations are often dependent, struggle to scale to complex materials in many state-of-the-art disciplines such as the design of high entropy alloys or multicomponent catalysts. To address this issue, we adapt sampling tools built upon machine-learning based generative modeling to the materials space by transforming them into the semi-grand canonical ensemble. Furthermore, we show that the resulting models are transferable across wide-ranges of thermodynamic conditions and can be implemented with any internal energy model U, allowing integration into many existing materials workflows. We demonstrate the applicability of this approach to the simulation of benchmark systems (AgPd, CuAu) that exhibit diverse thermodynamic behavior in their phase diagrams. Finally, we discuss remaining challenges in model development and promising research directions for future improvements.
        △ Less",https://arxiv.org/pdf/2107.05109
25,Gradient domain machine learning with complex kernels: improving the accuracy of PES and force fields for large molecules,"['Kasra Asnaashari', 'Roman V. Krems']","The generalization accuracy of machine learning models of potential energy surfaces (PES) and force fields (FF) for large polyatomic molecules can be generally improved either by increasing the number of training points or by improving the models. In order to build accurate models based on expensive high-level ab initio calculations, much of recent work has focused on the latter. In particular, it has been shown that gradient domain machine learning (GDML) models produce accurate results for high-dimensional molecular systems with a small number of ab initio calculations. The present work extends GDML to models with complex kernels built to maximize inference from a small number of molecular geometries. We illustrate that GDML models can be improved by increasing the complexity of underlying kernels through a greedy search algorithm using Bayesian information criterion as the model selection metric. We show that this requires including anisotropy into kernel functions and produces models with significantly smaller generalization errors. The results are presented for ethanol, uracil, malonaldehyde and aspirin. For aspirin, the model with complex kernels trained by forces at 1000 randomly sampled molecular geometries produces a global 57-dimensional PES with the mean absolute accuracy 0.177 kcal/mol (61.9 cm^{-1}) and FFs with the mean absolute error 0.457 kcal/mol Å^{-1}.
        △ Less",https://arxiv.org/pdf/2107.04779
26,"Machine Learning for Stuttering Identification: Review, Challenges & Future Directions","['Shakeel Ahmad Sheikh', 'Md Sahidullah', 'Fabrice Hirsch', 'Slim Ouni']","Stuttering is a speech disorder during which the flow of speech is interrupted by involuntary pauses and repetition of sounds. Stuttering identification is an interesting interdisciplinary domain research problem which involves pathology, psychology, acoustics, and signal processing that makes it hard and complicated to detect. Recent developments in machine and deep learning have dramatically revolutionized speech domain, however minimal attention has been given to stuttering identification. This work fills the gap by trying to bring researchers together from interdisciplinary fields. In this paper, we review comprehensively acoustic features, statistical and deep learning based stuttering/disfluency classification methods. We also present several challenges and possible future directions.
        △ Less",https://arxiv.org/pdf/2107.04057
27,"Prediction of Solar Proton Events with Machine Learning: Comparison with Operational Forecasts and ""All-Clear"" Perspectives","['Viacheslav Sadykov', 'Alexander Kosovichev', 'Irina Kitiashvili', 'Vincent Oria', 'Gelu M Nita', 'Egor Illarionov', ""Patrick O'Keefe"", 'Yucheng Jiang', 'Sheldon Fereira', 'Aatiya Ali']","Solar Energetic Particle events (SEPs) are among the most dangerous transient phenomena of solar activity. As hazardous radiation, SEPs may affect the health of astronauts in outer space and adversely impact current and future space exploration. In this paper, we consider the problem of daily prediction of Solar Proton Events (SPEs) based on the characteristics of the magnetic fields in solar Active Regions (ARs), preceding soft X-ray and proton fluxes, and statistics of solar radio bursts. The machine learning (ML) algorithm uses an artificial neural network of custom architecture designed for whole-Sun input. The predictions of the ML model are compared with the SWPC NOAA operational forecasts of SPEs. Our preliminary results indicate that 1) for the AR-based predictions, it is necessary to take into account ARs at the western limb and on the far side of the Sun; 2) characteristics of the preceding proton flux represent the most valuable input for prediction; 3) daily median characteristics of ARs and the counts of type II, III, and IV radio bursts may be excluded from the forecast without performance loss; and 4) ML-based forecasts outperform SWPC NOAA forecasts in situations in which missing SPE events is very undesirable. The introduced approach indicates the possibility of developing robust ""all-clear"" SPE forecasts by employing machine learning methods.
        △ Less",https://arxiv.org/pdf/2107.03911
28,Designing Machine Learning Pipeline Toolkit for AutoML Surrogate Modeling Optimization,"['Paulito P. Palmes', 'Akihiro Kishimoto', 'Radu Marinescu', 'Parikshit Ram', 'Elizabeth Daly']","The pipeline optimization problem in machine learning requires simultaneous optimization of pipeline structures and parameter adaptation of their elements. Having an elegant way to express these structures can help lessen the complexity in the management and analysis of their performances together with the different choices of optimization strategies. With these issues in mind, we created the AutoMLPipeline (AMLP) toolkit which facilitates the creation and evaluation of complex machine learning pipeline structures using simple expressions. We use AMLP to find optimal pipeline signatures, datamine them, and use these datamined features to speed-up learning and prediction. We formulated a two-stage pipeline optimization with surrogate modeling in AMLP which outperforms other AutoML approaches with a 4-hour time budget in less than 5 minutes of AMLP computation time.
        △ Less",https://arxiv.org/pdf/2107.01253
29,Ensemble Learning-Based Approach for Improving Generalization Capability of Machine Reading Comprehension Systems,"['Razieh Baradaran', 'Hossein Amirkhani']","Machine Reading Comprehension (MRC) is an active field in natural language processing with many successful developed models in recent years. Despite their high in-distribution accuracy, these models suffer from two issues: high training cost and low out-of-distribution accuracy. Even though some approaches have been presented to tackle the generalization problem, they have high, intolerable training costs. In this paper, we investigate the effect of ensemble learning approach to improve generalization of MRC systems without retraining a big model. After separately training the base models with different structures on different datasets, they are ensembled using weighting and stacking approaches in probabilistic and non-probabilistic settings. Three configurations are investigated including heterogeneous, homogeneous, and hybrid on eight datasets and six state-of-the-art models. We identify the important factors in the effectiveness of ensemble methods. Also, we compare the robustness of ensemble and fine-tuned models against data distribution shifts. The experimental results show the effectiveness and robustness of the ensemble approach in improving the out-of-distribution accuracy of MRC systems, especially when the base models are similar in accuracies.
        △ Less",https://arxiv.org/pdf/2107.00368
30,Pairing Conceptual Modeling with Machine Learning,"['Wolfgang Maass', 'Veda C. Storey']","Both conceptual modeling and machine learning have long been recognized as important areas of research. With the increasing emphasis on digitizing and processing large amounts of data for business and other applications, it would be helpful to consider how these areas of research can complement each other. To understand how they can be paired, we provide an overview of machine learning foundations and development cycle. We then examine how conceptual modeling can be applied to machine learning and propose a framework for incorporating conceptual modeling into data science projects. The framework is illustrated by applying it to a healthcare application. For the inverse pairing, machine learning can impact conceptual modeling through text and rule mining, as well as knowledge graphs. The pairing of conceptual modeling and machine learning in this this way should help lay the foundations for future research.
        △ Less",https://arxiv.org/pdf/2106.14251
31,"HASI: Hardware-Accelerated Stochastic Inference, A Defense Against Adversarial Machine Learning Attacks","['Mohammad Hossein Samavatian', 'Saikat Majumdar', 'Kristin Barber', 'Radu Teodorescu']","Deep Neural Networks (DNNs) are employed in an increasing number of applications, some of which are safety critical. Unfortunately, DNNs are known to be vulnerable to so-called adversarial attacks that manipulate inputs to cause incorrect results that can be beneficial to an attacker or damaging to the victim. Multiple defenses have been proposed to increase the robustness of DNNs. In general, these defenses have high overhead, some require attack-specific re-training of the model or careful tuning to adapt to different attacks.
  This paper presents HASI, a hardware-accelerated defense that uses a process we call stochastic inference to detect adversarial inputs. We show that by carefully injecting noise into the model at inference time, we can differentiate adversarial inputs from benign ones. HASI uses the output distribution characteristics of noisy inference compared to a non-noisy reference to detect adversarial inputs. We show an adversarial detection rate of 86% when applied to VGG16 and 93% when applied to ResNet50, which exceeds the detection rate of the state of the art approaches, with a much lower overhead. We demonstrate two software/hardware-accelerated co-designs, which reduces the performance impact of stochastic inference to 1.58X-2X relative to the unprotected baseline, compared to 15X-20X overhead for a software-only GPU implementation.
        △ Less",https://arxiv.org/pdf/2106.05825
32,Matrix Product State Pre-Training for Quantum Machine Learning,"['James Dborin', 'Fergus Barratt', 'Vinul Wimalaweera', 'Lewis Wright', 'Andrew G. Green']","Hybrid Quantum-Classical algorithms are a promising candidate for developing uses for NISQ devices. In particular, Parametrised Quantum Circuits (PQCs) paired with classical optimizers have been used as a basis for quantum chemistry and quantum optimization problems. Training PQCs relies on methods to overcome the fact that the gradients of PQCs vanish exponentially in the size of the circuits used. Tensor network methods are being increasingly used as a classical machine learning tool, as well as a tool for studying quantum systems. We introduce a circuit pre-training method based on matrix product state machine learning methods, and demonstrate that it accelerates training of PQCs for both supervised learning, energy minimization, and combinatorial optimization.
        △ Less",https://arxiv.org/pdf/2106.05742
33,Machine Learning in weakly nonlinear systems: A Case study on Significant wave heights,['Pujan Pokhrel'],"This paper proposes a machine learning method based on the Extra Trees (ET) algorithm for forecasting Significant Wave Heights in oceanic waters. To derive multiple features from the CDIP buoys, which make point measurements, we first nowcast various parameters and then forecast them at 30-min intervals. The proposed algorithm has Scatter Index (SI), Bias, Correlation Coefficient, Root Mean Squared Error (RMSE) of 0.130, -0.002, 0.97, and 0.14, respectively, for one day ahead prediction and 0.110, -0.001, 0.98, and 0.122, respectively, for 14-day ahead prediction on the testing dataset. While other state-of-the-art methods can only forecast up to 120 hours ahead, we extend it further to 14 days. Our proposed setup includes spectral features, hv-block cross-validation, and stringent QC criteria. The proposed algorithm performs significantly better than the state-of-the-art methods commonly used for significant wave height forecasting for one-day ahead prediction. Moreover, the improved performance of the proposed machine learning method compared to the numerical methods shows that this performance can be extended to even longer periods allowing for early prediction of significant wave heights in oceanic waters.
        △ Less",https://arxiv.org/pdf/2105.08583
34,Machine learning force fields based on local parametrization of dispersion interactions: Application to the phase diagram of C_{60},"['Heikki Muhli', 'Xi Chen', 'Albert P. Bartók', 'Patricia Hernández-León', 'Gábor Csányi', 'Tapio Ala-Nissila', 'Miguel A. Caro']","We present a comprehensive methodology to enable addition of van der Waals (vdW) corrections to machine learning (ML) atomistic force fields. Using a Gaussian approximation potential (GAP) [Bartók et al., Phys. Rev. Lett. 104, 136403 (2010)] as baseline, we accurately machine learn a local model of atomic polarizabilities based on Hirshfeld volume partitioning of the charge density [Tkatchenko and Scheffler, Phys. Rev. Lett. 102, 073005 (2009)]. These environment-dependent polarizabilities are then used to parametrize a screened London-dispersion approximation to the vdW interactions. Our ML vdW model only needs to learn the charge density partitioning implicitly, by learning the reference Hirshfeld volumes from density functional theory (DFT). In practice, we can predict accurate Hirshfeld volumes from the knowledge of the local atomic environment (atomic positions) alone, making the model highly computationally efficient. For additional efficiency, our ML model of atomic polarizabilities reuses the same many-body atomic descriptors used for the underlying GAP learning of bonded interatomic interactions. We also show how the method enables straightforward computation of gradients of the observables, even when these remain challenging for the reference method (e.g., calculating gradients of the Hirshfeld volumes in DFT). Finally, we demonstrate the approach by studying the phase diagram of C_{60}, where vdW effects are important. The need for a highly accurate vdW-inclusive reactive force field is highlighted by modeling the decomposition of the C_{60} molecules taking place at high pressures and temperatures.
        △ Less",https://arxiv.org/pdf/2105.02525
35,Via Machinae: Searching for Stellar Streams using Unsupervised Machine Learning,"['David Shih', 'Matthew R. Buckley', 'Lina Necib', 'John Tamanas']","We develop a new machine learning algorithm, Via Machinae, to identify cold stellar streams in data from the Gaia telescope. Via Machinae is based on ANODE, a general method that uses conditional density estimation and sideband interpolation to detect local overdensities in the data in a model agnostic way. By applying ANODE to the positions, proper motions, and photometry of stars observed by Gaia, Via Machinae obtains a collection of those stars deemed most likely to belong to a stellar stream. We further apply an automated line-finding method based on the Hough transform to search for line-like features in patches of the sky. In this paper, we describe the Via Machinae algorithm in detail and demonstrate our approach on the prominent stream GD-1. A companion paper contains our identification of other known stellar streams as well as new stellar stream candidates from Via Machinae. Though some parts of the algorithm are tuned to increase sensitivity to cold streams, the Via Machinae technique itself does not rely on astrophysical assumptions, such as the potential of the Milky Way or stellar isochrones. This flexibility suggests that it may have further applications in identifying other anomalous structures within the Gaia dataset, for example debris flow and globular clusters.
        △ Less",https://arxiv.org/pdf/2104.12789
36,Impact of quantum-chemical metrics on the machine learning prediction of electron density,"['Ksenia R. Briling', 'Alberto Fabrizio', 'Clemence Corminboeuf']","Machine learning (ML) algorithms have undergone an explosive development impacting every aspect of computational chemistry. To obtain reliable predictions, one needs to maintain the proper balance between the black-box nature of ML frameworks and the physics of the target properties. One of the most appealing quantum-chemical properties for regression models is the electron density, and some of us recently proposed a transferable and scalable model based on the decomposition of the density onto an atom-centered basis set. The decomposition, as well as the training of the model, is at its core a minimization of some loss function, which can be arbitrarily chosen and may lead to results of different quality. Well-studied in the context of density fitting (DF), the impact of the metric on the performance of ML models has not been analyzed yet. In this work, we compare predictions obtained using the overlap and the Coulomb-repulsion metrics for both decomposition and training. As expected, the Coulomb metric used as both the DF and ML loss functions leads to the best results for the electrostatic potential and dipole moments. The origin of this difference lies in the fact that the model is not constrained to predict densities that integrate to the exact number of electrons N. Since an \textit{a posteriori} correction for the number of electrons decreases the errors, we proposed a modification of the model where N is included directly into the kernel function, which allowed to lower the errors on the test and out-of-sample sets.
        △ Less",https://arxiv.org/pdf/2104.12457
37,Machine Learning Directed Optimization of Classical Molecular Modeling Force Fields,"['Bridgette J. Befort', 'Ryan S. DeFever', 'Garrett M. Tow', 'Alexander W. Dowling', 'Edward J. Maginn']","Accurate force fields are necessary for predictive molecular simulations. However, developing force fields that accurately reproduce experimental properties is challenging. Here, we present a machine learning directed, multiobjective optimization workflow for force field parameterization that evaluates millions of prospective force field parameter sets while requiring only a small fraction of them to be tested with molecular simulations. We demonstrate the generality of the approach and identify multiple low-error parameter sets for two distinct test cases: simulations of hydrofluorocarbon (HFC) vapor-liquid equilibrium (VLE) and an ammonium perchlorate (AP) crystal phase. We discuss the challenges and implications of our force field optimization workflow.
        △ Less",https://arxiv.org/pdf/2103.03208
38,Modelling Sovereign Credit Ratings: Evaluating the Accuracy and Driving Factors using Machine Learning Techniques,"['Bart H. L. Overes', 'Michel van der Wel']","Sovereign credit ratings summarize the creditworthiness of countries. These ratings have a large influence on the economy and the yields at which governments can issue new debt. This paper investigates the use of a Multilayer Perceptron (MLP), Classification and Regression Trees (CART), Support Vector Machines (SVM), Naïve Bayes (NB), and an Ordered Logit (OL) model for the prediction of sovereign credit ratings. We show that MLP is best suited for predicting sovereign credit ratings, with a random cross-validated accuracy of 68%, followed by CART (59%), SVM (41%), NB (38%), and OL (33%). Investigation of the determining factors shows that there is some heterogeneity in the important variables across the models. However, the two models with the highest out-of-sample predictive accuracy, MLP and CART, show a lot of similarities in the influential variables, with regulatory quality, and GDP per capita as common important variables. Consistent with economic theory, a higher regulatory quality and/or GDP per capita are associated with a higher credit rating.
        △ Less",https://arxiv.org/pdf/2101.12684
39,Double machine learning for sample selection models,"['Michela Bia', 'Martin Huber', 'Lukáš Lafférs']","This paper considers the evaluation of discretely distributed treatments when outcomes are only observed for a subpopulation due to sample selection or outcome attrition. For identification, we combine a selection-on-observables assumption for treatment assignment with either selection-on-observables or instrumental variable assumptions concerning the outcome attrition/sample selection process. We also consider dynamic confounding, meaning that covariates that jointly affect sample selection and the outcome may (at least partly) be influenced by the treatment. To control in a data-driven way for a potentially high dimensional set of pre- and/or post-treatment covariates, we adapt the double machine learning framework for treatment evaluation to sample selection problems. We make use of (a) Neyman-orthogonal, doubly robust, and efficient score functions, which imply the robustness of treatment effect estimation to moderate regularization biases in the machine learning-based estimation of the outcome, treatment, or sample selection models and (b) sample splitting (or cross-fitting) to prevent overfitting bias. We demonstrate that the proposed estimators are asymptotically normal and root-n consistent under specific regularity conditions concerning the machine learners and investigate their finite sample properties in a simulation study. We also apply our proposed methodology to the Job Corps data for evaluating the effect of training on hourly wages which are only observed conditional on employment. The estimator is available in the causalweight package for the statistical software R.
        △ Less",https://arxiv.org/pdf/2012.00745
40,Performance Analysis on Machine Learning-Based Channel Estimation,"['Kai Mei', 'Jun Liu', 'Xiaochen Zhang', 'Nandana Rajatheva', 'Jibo Wei']","Recently, machine learning-based channel estimation has attracted much attention. The performance of machine learning-based estimation has been validated by simulation experiments. However, little attention has been paid to the theoretical performance analysis. In this paper, we investigate the mean square error (MSE) performance of machine learning-based estimation. Hypothesis testing is employed to analyze its MSE upper bound. Furthermore, we build a statistical model for hypothesis testing, which holds when the linear learning module with a low input dimension is used in machine learning-based channel estimation, and derive a clear analytical relation between the size of the training data and performance. Then, we simulate the machine learning-based channel estimation in orthogonal frequency division multiplexing (OFDM) systems to verify our analysis results. Finally, the design considerations for the situation where only limited training data is available are discussed. In this situation, our analysis results can be applied to assess the performance and support the design of machine learning-based channel estimation.
        △ Less",https://arxiv.org/pdf/1911.03886
